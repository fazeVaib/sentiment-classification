{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### HW2 - Part 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "'''\n",
    "Importing all libraries\n",
    "'''\n",
    "from copy import deepcopy\n",
    "from numpy import argmax\n",
    "import contractions\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import torch\n",
    "import gensim\n",
    "import warnings\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy import vstack\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import gensim.downloader as api\n",
    "from sklearn.svm import LinearSVC as SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.linear_model import Perceptron\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('wordnet')\n",
    "warnings.filterwarnings('ignore')\n",
    "CUDA_LAUNCH_BLOCKING = 1\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/darkghost/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a class \"DataTransformation\" to manage preprocessing of data\n",
    "\n",
    "Usage of functions:\n",
    "\n",
    "1. read_file(): reads the tsv file and returns the dataframe\n",
    "2. df_formation(): reads the dataframe and picks 50k reviews of each star rating and returns the final combined df\n",
    "3. label() and apply_label(): To apply 1, 2 or 3 label to the reviews\n",
    "4. remove_html_url(): removes the HTML and URL from the reviews \n",
    "5. tokenize(): tokenizes the reviews\n",
    "6. without_preprocess(): returns df without doing all preprocessing, just tokenized\n",
    "7. with_preprocess(): returns preprocessed and tokenized reviews\n",
    "8. train_test_split(): splits the df into 80%-20% train-test split"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class DataTranformation(object):\n",
    "\n",
    "    def __init__(self, filename, preprocess):\n",
    "        self.filename = filename\n",
    "        self.random_state = 10\n",
    "        self.n = 50000\n",
    "        self.preprocess = preprocess\n",
    "        print(\"Preproces: \" + str(preprocess))\n",
    "\n",
    "    def read_file(self, error_bad_lines=False, warn_bad_lines=False, sep=\"\\t\"):\n",
    "        df = pd.read_csv(self.filename, sep=sep,\n",
    "                         error_bad_lines=error_bad_lines, warn_bad_lines=warn_bad_lines)\n",
    "        df = df.dropna()\n",
    "        return df\n",
    "\n",
    "    def df_formation(self, row1='review_body', row2='star_rating', ):\n",
    "        df = self.read_file()\n",
    "        df = df[[row1, row2]]\n",
    "        df = df.dropna()\n",
    "\n",
    "        dataset = pd.concat([df[df['star_rating'] == 1].sample(n=50000, random_state=10),\n",
    "                             df[df['star_rating'] == 2].sample(\n",
    "                                 n=50000, random_state=10),\n",
    "                             df[df['star_rating'] == 3].sample(\n",
    "                                 n=50000, random_state=10),\n",
    "                             df[df['star_rating'] == 4].sample(\n",
    "                                 n=50000, random_state=10),\n",
    "                             df[df['star_rating'] == 5].sample(n=50000, random_state=10)])\n",
    "\n",
    "        dataset = dataset.reset_index(drop=True)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def label(self, rows):\n",
    "        if rows.star_rating > 3:\n",
    "            return 1\n",
    "        elif rows.star_rating < 3:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "    def apply_label(self):\n",
    "        dataset = self.df_formation()\n",
    "        dataset['label'] = dataset.apply(lambda row: self.label(row), axis=1)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def remove_html_and_url(self, s):\n",
    "        s = re.sub(\n",
    "            r'(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)', '', s, flags=re.MULTILINE)\n",
    "        soup = BeautifulSoup(s, 'html.parser')\n",
    "        s = soup.get_text()\n",
    "        return s\n",
    "\n",
    "    def tokenize(self, s):\n",
    "        text_tokens = word_tokenize(s)\n",
    "        return text_tokens\n",
    "\n",
    "    def without_preprocess(self):\n",
    "        dataset = self.apply_label()\n",
    "        dataset.review_body = dataset.review_body.apply(self.tokenize)\n",
    "        return dataset\n",
    "\n",
    "    def with_preprocess(self):\n",
    "        dataset = self.apply_label()\n",
    "        dataset.review_body = dataset.review_body.str.lower()\n",
    "\n",
    "        dataset.review_body = dataset.review_body.apply(\n",
    "            lambda s: self.remove_html_and_url(s))\n",
    "        dataset.review_body = dataset.review_body.apply(\n",
    "            lambda s: re.sub(\"[^a-zA-Z']+\", \" \", s))\n",
    "        dataset.review_body = dataset.review_body.apply(\n",
    "            lambda s: re.sub(' +', ' ', s))\n",
    "\n",
    "        dataset.review_body = dataset.review_body.apply(self.tokenize)\n",
    "\n",
    "        dataset.dropna()\n",
    "        return dataset\n",
    "\n",
    "    def train_test_split(self):\n",
    "\n",
    "        if self.preprocess:\n",
    "            dataset = self.with_preprocess()\n",
    "        else:\n",
    "            dataset = self.without_preprocess()\n",
    "\n",
    "        train = dataset.sample(frac=0.8, random_state=200)\n",
    "        test = dataset.drop(train.index)\n",
    "        train = train.reset_index(drop=True)\n",
    "        test = test.reset_index(drop=True)\n",
    "\n",
    "        return train, test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating class Vectorization to generate feature vectors of the words based on the requirements\n",
    "\n",
    "Functions are as follows:\n",
    "\n",
    "1. get_mean_vector(): returns feature vector vlues for every word in the review\n",
    "2. feature_extraction(): Either pads or takes first 10 vectors or calculate mean vector for full review\n",
    "3. pad_review(): pads the reviews to the desired length\n",
    "4. join_words(): list of words in converted to back to one sentence"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class Vectorization(object):\n",
    "\n",
    "    def __init__(self, model, dataset, model_type=\"model\", classification=\"binary\", mode=\"mean\", pad=False):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.model_type = model_type  # our own model or pretrained\n",
    "        self.classification = classification  # binary or multi-class\n",
    "        if self.model_type == \"pretrained\":\n",
    "            self.vocab = self.model\n",
    "        if self.model_type == \"model\":\n",
    "            self.vocab = self.model.wv\n",
    "\n",
    "        self.mode = mode\n",
    "        self.pad = pad\n",
    "\n",
    "        print(\"Vectorizing training dataset....\")\n",
    "        print(\"Model Type: \" + self.model_type)\n",
    "        print(\"Classification: \" + self.classification)\n",
    "\n",
    "    def get_mean_vector(self, data_review_body, data_label):\n",
    "\n",
    "        if self.classification == \"binary\":\n",
    "            if data_label != 3:\n",
    "                if self.model_type == \"model\":\n",
    "                    words = [\n",
    "                        word for word in data_review_body if word in self.vocab.index_to_key]\n",
    "                    if len(words) >= 1:\n",
    "                        rev = []\n",
    "                        for word in words:\n",
    "                            rev.append(np.array(self.vocab[word]))\n",
    "\n",
    "                        if type(data_label) is not int:\n",
    "                            print(\"Found\")\n",
    "                        return rev, data_label\n",
    "                else:\n",
    "                    words = [\n",
    "                        word for word in data_review_body if word in self.vocab]\n",
    "                    if len(words) >= 1:\n",
    "                        rev = []\n",
    "                        for word in words:\n",
    "                            rev.append(np.array(self.vocab[word]))\n",
    "\n",
    "                        if type(data_label) is not int:\n",
    "                            print(\"Found\")\n",
    "                        return rev, data_label\n",
    "\n",
    "        else:\n",
    "            if self.model_type == \"mode\":\n",
    "                words = [\n",
    "                    word for word in data_review_body if word in self.vocab.index_to_key]\n",
    "                if len(words) >= 1:\n",
    "                    rev = []\n",
    "                    for word in words:\n",
    "                        rev.append(np.array(self.vocab[word]))\n",
    "                    return rev, data_label\n",
    "            else:\n",
    "                words = [word for word in data_review_body if word in self.vocab]\n",
    "                if len(words) >= 1:\n",
    "                    rev = []\n",
    "                    for word in words:\n",
    "                        rev.append(np.array(self.vocab[word]))\n",
    "                    return rev, data_label\n",
    "\n",
    "    def feature_extraction(self):\n",
    "        feature = []\n",
    "        y_label = []\n",
    "        # print(self.vocab.index_to_key)\n",
    "        for data_review_body, data_label in zip(self.dataset.review_body, self.dataset.label):\n",
    "            try:\n",
    "                x, y = self.get_mean_vector(data_review_body, data_label)\n",
    "                if self.pad:\n",
    "                    if len(x) >= 50:\n",
    "                        feature.append(x[:50])\n",
    "                        y_label.append(y)\n",
    "                    else:\n",
    "                        feature.append(x)\n",
    "                        y_label.append(y)\n",
    "                else:\n",
    "                    if self.mode == \"vec\":\n",
    "                        if len(x) >= 10:\n",
    "                            feature.append(x[:10])\n",
    "                            y_label.append(y)\n",
    "                    else:\n",
    "                        feature.append(np.mean(x, axis=0))\n",
    "                        y_label.append(y)\n",
    "            except:\n",
    "                pass\n",
    "        print(\"Vectorization Completed\")\n",
    "        return feature, y_label\n",
    "\n",
    "    def pad_review(self, review, seq_len):\n",
    "\n",
    "        features = np.zeros((seq_len, 300), dtype=float)\n",
    "        features[-len(review):] = np.array(review)[:seq_len]\n",
    "\n",
    "        return features\n",
    "\n",
    "    def join_words(self, x):\n",
    "        y = \"\"\n",
    "        for ele in x:\n",
    "            y = ' '.join(ele)\n",
    "        return y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sentence class returns one review at a time from the dataset through the use of __iter__."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class Sentence(object):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __iter__(self):\n",
    "        for row in self.dataset:\n",
    "            yield row"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Class to train and evaluate the Perceptron"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "class Percept(object):\n",
    "\n",
    "    def __init__(self, X_train, Y_train, X_test, Y_test, max_iter=100, random_state=20, eta0=0.01, verbose=0):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.X_test = X_test\n",
    "        self.Y_test = Y_test\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "        self.eta0 = eta0\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def metrics(self, true, pred):\n",
    "        tn, fp, fn, tp = cm(true, pred).ravel()\n",
    "        acc = (tp + tn)/(tn + fp + fn + tp)\n",
    "        prec = tp/(tp + fp)\n",
    "        rec = tp / (tp + fn)\n",
    "        f1 = 2*(rec * prec) / (rec + prec)\n",
    "        return [acc, prec, rec, f1]\n",
    "\n",
    "    def print_seq(self, score_list):\n",
    "        print(\"%.6f\" % score_list[0], \" %.6f\" % score_list[1],\n",
    "              \" %.6f\" % score_list[2], \" %.6f\" % score_list[3])\n",
    "\n",
    "    def perceptron_model(self):\n",
    "        percept = Perceptron(\n",
    "            max_iter=self.max_iter, random_state=self.random_state, eta0=self.eta0, verbose=self.verbose)\n",
    "\n",
    "        print(\"Fitting the Model...\")\n",
    "        percept.fit(self.X_train, self.Y_train)\n",
    "        return percept\n",
    "\n",
    "    def evaluation(self):\n",
    "        percept = self.perceptron_model()\n",
    "        Y_train_pred = percept.predict(self.X_train)\n",
    "        train_score = self.metrics(self.Y_train, Y_train_pred)\n",
    "        Y_test_pred = percept.predict(self.X_test)\n",
    "        test_score = self.metrics(self.Y_test, Y_test_pred)\n",
    "\n",
    "        print(\"Training Score\")\n",
    "        self.print_seq(train_score)\n",
    "\n",
    "        print(\"Testing Score\")\n",
    "        self.print_seq(test_score)\n",
    "\n",
    "        return test_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Class to train and evaluate the SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "class SVM(object):\n",
    "\n",
    "    def __init__(self, X_train, Y_train, X_test, Y_test, max_iter=500):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.X_test = X_test\n",
    "        self.Y_test = Y_test\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def intitalize_model(self):\n",
    "        # Linear SVM\n",
    "        svc = SVC(max_iter=self.max_iter)\n",
    "\n",
    "        print(\"Fitting the SVM\")\n",
    "        svc_model = svc.fit(self.X_train, self.Y_train)\n",
    "        return svc_model\n",
    "\n",
    "    def print_seq(self, score_list):\n",
    "        print(\"%.6f\" % score_list[0], \" %.6f\" % score_list[1],\n",
    "              \" %.6f\" % score_list[2], \" %.6f\" % score_list[3])\n",
    "\n",
    "    def metrics(self, true, pred):\n",
    "        tn, fp, fn, tp = cm(true, pred).ravel()\n",
    "        acc = (tp + tn)/(tn + fp + fn + tp)\n",
    "        prec = tp/(tp + fp)\n",
    "        rec = tp / (tp + fn)\n",
    "        f1 = 2*(rec * prec) / (rec + prec)\n",
    "        return [acc, prec, rec, f1]\n",
    "\n",
    "    def evaluation(self):\n",
    "        svc_model = self.intitalize_model()\n",
    "        Y_train_pred = svc_model.predict(self.X_train)\n",
    "        train_score = self.metrics(self.Y_train, Y_train_pred)\n",
    "\n",
    "        Y_test_pred = svc_model.predict(self.X_test)\n",
    "        test_score = self.metrics(self.Y_test, Y_test_pred)\n",
    "\n",
    "        print(\"Training Score\")\n",
    "        self.print_seq(train_score)\n",
    "\n",
    "        print(\"Testing Score\")\n",
    "        self.print_seq(test_score)\n",
    "\n",
    "        return test_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reading the file and carrying out preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "filename = \"./amazon_reviews_us_Kitchen_v1_00.tsv\"\n",
    "dt = DataTranformation(filename, True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Preproces: True\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Splitting data and generating pretrained and self-trained word2vec models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "train, test = dt.train_test_split()\n",
    "\n",
    "sentences = Sentence(train['review_body'])\n",
    "\n",
    "pretrained_model = api.load('word2vec-google-news-300')\n",
    "model = gensim.models.Word2Vec(sentences, vector_size = 300, min_count = 10, window = 11, seed = 200)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Semantic similarities in pretrained model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "\n",
    "print(pretrained_model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1))\n",
    "print(pretrained_model.similarity('excellent', 'outstanding'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('queen', 0.7118193507194519)]\n",
      "0.5567486\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Semantic Similarities in Self-Trained Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "print(model.wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=1))\n",
    "print(model.wv.similarity('excellent', 'outstanding'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('arthur', 0.536632239818573)]\n",
      "0.7561389\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the obervation, it looks like finding most similar word works better in pretrained model an it works better, but similarities between two words in some cases are better in our self-trained model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Self-trained model feature extraction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "vec_train = Vectorization(model = model, dataset = train)\n",
    "vec_test = Vectorization(model, test)\n",
    "\n",
    "X_train_model, Y_train_model = vec_train.feature_extraction()\n",
    "X_test_model, Y_test_model = vec_test.feature_extraction()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Vectorizing training dataset....\n",
      "Model Type: model\n",
      "Classification: binary\n",
      "Vectorizing training dataset....\n",
      "Model Type: model\n",
      "Classification: binary\n",
      "Vectorization Completed\n",
      "Vectorization Completed\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pre-trained model feature extraction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "vec2_train = Vectorization(model = pretrained_model, dataset = train, model_type = \"pretrained\")\n",
    "vec2_test = Vectorization(model = pretrained_model, dataset = test, model_type = \"pretrained\")\n",
    "\n",
    "X_train_pre, Y_train_pre = vec2_train.feature_extraction()\n",
    "X_test_pre, Y_test_pre = vec2_test.feature_extraction()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Vectorizing training dataset....\n",
      "Model Type: pretrained\n",
      "Classification: binary\n",
      "Vectorizing training dataset....\n",
      "Model Type: pretrained\n",
      "Classification: binary\n",
      "Vectorization Completed\n",
      "Vectorization Completed\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TF-IDF feature extraction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def get_tfidf(train, test):\n",
    "    train_x = train.apply(lambda x: \" \".join(ele for ele in x))\n",
    "    test_x = test.apply(lambda x: \" \".join(ele for ele in x))\n",
    "    tfidf_vect = TfidfVectorizer(min_df = 0.001)\n",
    "    train_x_vectors = tfidf_vect.fit_transform(train_x)\n",
    "    train_x_vectors = pd.DataFrame(train_x_vectors.toarray(), columns = tfidf_vect.get_feature_names())\n",
    "    test_x_vectors = tfidf_vect.transform(test_x)\n",
    "    test_x_vectors = pd.DataFrame(test_x_vectors.toarray(), columns = tfidf_vect.get_feature_names())\n",
    "    return train_x_vectors, test_x_vectors"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "train_tfidf = train[train.label != 3].reset_index(drop = True)\n",
    "test_tfidf = test[test.label != 3].reset_index(drop = True)\n",
    "X_train_tfidf, X_test_tfidf = get_tfidf(train_tfidf.review_body, test_tfidf.review_body)\n",
    "Y_train_tfidf = train_tfidf['label']\n",
    "Y_test_tfidf = test_tfidf['label']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training Perceptron on all three types of feature vectors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "per = Percept(X_train = X_train_model, Y_train = Y_train_model, X_test = X_test_model, Y_test = Y_test_model)\n",
    "model_test_score = per.evaluation()\n",
    "\n",
    "per2 = Percept(X_train = X_train_pre, Y_train = Y_train_pre, X_test = X_test_pre, Y_test = Y_test_pre)\n",
    "model_pre_test_score = per2.evaluation()\n",
    "\n",
    "per3 = Percept(X_train = X_train_tfidf, Y_train = Y_train_tfidf, X_test = X_test_tfidf, Y_test = Y_test_tfidf)\n",
    "model_tfidf_test_score = per3.evaluation()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting the Model...\n",
      "Training Score\n",
      "0.828443  0.793716  0.886345  0.837477\n",
      "Testing Score\n",
      "0.829329  0.798938  0.885727  0.840097\n",
      "Fitting the Model...\n",
      "Training Score\n",
      "0.763225  0.690646  0.951428  0.800329\n",
      "Testing Score\n",
      "0.767361  0.698484  0.950958  0.805398\n",
      "Fitting the Model...\n",
      "Training Score\n",
      "0.783854  0.956979  0.593071  0.732307\n",
      "Testing Score\n",
      "0.778406  0.954277  0.590347  0.729439\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the observation, perceptron with self-trained feature vector model performed the best in terms of accuracy on current dataset, whereas pretrained model and tf-idf one performed similar on the basis of accuracy.\n",
    "\n",
    "The results may vary according to the number of iterations and learning rate. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training SVM on three types of Feature-vectors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "svm = SVM(X_train = X_train_model, Y_train = Y_train_model, X_test = X_test_model, Y_test = Y_test_model)\n",
    "svm_model_test_score = svm.evaluation()\n",
    "\n",
    "svm2 = SVM(X_train = X_train_pre, Y_train = Y_train_pre, X_test = X_test_pre, Y_test = Y_test_pre)\n",
    "svm_pre_test_score = svm2.evaluation()\n",
    "\n",
    "svm3 = SVM(X_train = X_train_tfidf, Y_train = Y_train_tfidf, X_test = X_test_tfidf, Y_test = Y_test_tfidf)\n",
    "svm_tfidf_test_score = svm3.evaluation()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting the SVM\n",
      "Training Score\n",
      "0.865810  0.852399  0.883987  0.867906\n",
      "Testing Score\n",
      "0.867006  0.858566  0.882659  0.870446\n",
      "Fitting the SVM\n",
      "Training Score\n",
      "0.829827  0.812739  0.856039  0.833827\n",
      "Testing Score\n",
      "0.830619  0.818565  0.854902  0.836339\n",
      "Fitting the SVM\n",
      "Training Score\n",
      "0.892099  0.888155  0.896438  0.892277\n",
      "Testing Score\n",
      "0.886275  0.885772  0.890021  0.887891\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the obervation, TF-IDF SVM performs the best in terms of accuracy, followed by Self-trained and Pretrained SVM.\n",
    "Results may vary according to type of kernel used and number of iterations."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For conclusion, Self-trained Word2Vec gives decent performance on average compared to other two feature extraction models for Perceptron and SVM. "
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b9cb23f9fb748a30e8d8bc81b9adb518e023d0772aa87870f409f813d831654e"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('ml': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}